import { useState, useEffect, useRef, useMemo, useCallback } from 'react';
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';
import { supabase } from '@/integrations/supabase/client';
import { AudioRecorder } from '@/lib/audio-recorder';
import { AudioStreamer } from '@/lib/audio-streamer';
import { audioContext } from '@/lib/utils';
import VolMeterWorket from '@/lib/worklets/vol-meter';

import { LiveConnectConfig } from "@google/genai";

export type UseOpenAIRealtimeResults = {
  client: RealtimeSession | null;
  agent: RealtimeAgent | null;
  setConfig: (config: LiveConnectConfig | { instructions?: string; tools?: any[] }) => void;
  config: { instructions?: string; tools?: any[] };
  model: string;
  setModel: (model: string) => void;
  connected: boolean;
  setupComplete: boolean;
  connect: () => Promise<void>;
  disconnect: () => Promise<void>;
  volume: number;
  // Geminiì™€ í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì„œë“œë“¤
  send: (parts: Array<{ text: string }>) => void;
  sendToolResponse: (response: any) => void;
  on: (event: string, handler: any) => void;
  off: (event: string, handler: any) => void;
};

// Gemini Type enumì„ OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜
function convertGeminiTypeToOpenAI(type: any): string {
  if (typeof type === 'string') {
    return type.toLowerCase();
  }
  // Type enum ê°ì²´ì¸ ê²½ìš°
  const typeStr = String(type);
  return typeStr.toLowerCase();
}

// Gemini parametersë¥¼ OpenAI í˜•ì‹ìœ¼ë¡œ ì¬ê·€ì ìœ¼ë¡œ ë³€í™˜
function convertParameters(params: any): any {
  if (!params || typeof params !== 'object') {
    return params;
  }

  const converted: any = {};
  
  for (const key in params) {
    if (key === 'type') {
      converted.type = convertGeminiTypeToOpenAI(params.type);
    } else if (key === 'properties' && typeof params.properties === 'object') {
      converted.properties = {};
      for (const propKey in params.properties) {
        converted.properties[propKey] = convertParameters(params.properties[propKey]);
      }
    } else if (key === 'items' && typeof params.items === 'object') {
      converted.items = convertParameters(params.items);
    } else if (key === 'enum' && Array.isArray(params.enum)) {
      converted.enum = params.enum;
    } else if (key === 'description') {
      converted.description = params.description;
    } else if (key === 'required' && Array.isArray(params.required)) {
      converted.required = params.required;
    }
  }
  
  return converted;
}

// Gemini configë¥¼ OpenAI instructionsë¡œ ë³€í™˜
function convertGeminiConfigToOpenAI(config: LiveConnectConfig): { instructions: string; tools: any[] } {
  let instructions = '';
  let tools: any[] = [];

  console.log('ğŸ”„ [OpenAI] Converting config:', {
    hasSystemInstruction: !!config.systemInstruction,
    hasParts: !!(config.systemInstruction as any)?.parts,
    partsLength: (config.systemInstruction as any)?.parts?.length || 0,
    hasTools: !!config.tools,
    toolsLength: config.tools?.length || 0
  });

  // systemInstructionì—ì„œ text ì¶”ì¶œ
  const systemInst = config.systemInstruction as any;
  if (systemInst?.parts) {
    instructions = systemInst.parts
      .map((part: any, index: number) => {
        console.log(`ğŸ“„ [OpenAI] Processing part ${index}:`, typeof part, part);
        if (typeof part === 'string') return part;
        if (part?.text) return part.text;
        return '';
      })
      .filter(Boolean)
      .join('\n');
    
    console.log('âœ… [OpenAI] Extracted instructions length:', instructions.length);
    if (instructions.length === 0) {
      console.error('âŒ [OpenAI] Warning: No instructions extracted from systemInstruction.parts!');
    }
  } else {
    console.warn('âš ï¸ [OpenAI] No systemInstruction.parts found in config');
  }

  // tools ë³€í™˜
  if (config.tools) {
    config.tools.forEach((tool: any, toolIndex: number) => {
      console.log(`ğŸ”§ [OpenAI] Processing tool ${toolIndex}:`, tool);
      if (tool.functionDeclarations) {
        tool.functionDeclarations.forEach((funcDecl: any, funcIndex: number) => {
          console.log(`  ğŸ“¦ Function ${funcIndex}:`, funcDecl.name);
          
          // Parametersë¥¼ OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜
          const convertedParams = funcDecl.parameters ? convertParameters(funcDecl.parameters) : {};
          
          console.log(`  ğŸ“ Converted parameters:`, JSON.stringify(convertedParams, null, 2));
          
          // OpenAI tool í˜•ì‹ìœ¼ë¡œ ë³€í™˜
          tools.push({
            type: 'function',
            function: {
              name: funcDecl.name,
              description: funcDecl.description,
              parameters: convertedParams
            }
          });
        });
      }
    });
    console.log('âœ… [OpenAI] Converted tools count:', tools.length);
  }

  return { instructions, tools };
}

export function useOpenAIRealtime(apiKey?: string): UseOpenAIRealtimeResults {
  const sessionRef = useRef<RealtimeSession | null>(null);
  const agentRef = useRef<RealtimeAgent | null>(null);
  const audioStreamerRef = useRef<AudioStreamer | null>(null);
  const audioRecorderRef = useRef<AudioRecorder | null>(null);
  const ephemeralKeyRef = useRef<string | null>(null);
  const eventHandlersRef = useRef<Map<string, Set<Function>>>(new Map());

  const [model, setModel] = useState<string>('gpt-realtime');
  const [config, setConfigState] = useState<{ instructions?: string; tools?: any[] }>({});
  const [connected, setConnected] = useState(false);
  const [setupComplete, setSetupComplete] = useState(false);
  const [volume, setVolume] = useState(0);
  const [isInitialized, setIsInitialized] = useState(false);
  const connectingRef = useRef(false); // ì¤‘ë³µ ì—°ê²° ë°©ì§€

  // Ephemeral key ìƒì„±
  const generateEphemeralKey = useCallback(async () => {
    try {
      // ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œëŠ” í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì§ì ‘ OpenAI API í˜¸ì¶œ (í…ŒìŠ¤íŠ¸ìš©)
      // í”„ë¡œë•ì…˜ì—ì„œëŠ” Supabase Functionì„ í†µí•´ í˜¸ì¶œí•´ì•¼ í•¨
      const isLocalDev = import.meta.env.DEV || window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1';
      
      if (isLocalDev && apiKey) {
        // ë¡œì»¬ ê°œë°œ: í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì§ì ‘ OpenAI API í˜¸ì¶œ
        console.log('ğŸ”‘ [OpenAI] ë¡œì»¬ ê°œë°œ í™˜ê²½ - í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì§ì ‘ API í˜¸ì¶œ');
        const response = await fetch('https://api.openai.com/v1/realtime/client_secrets', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            session: {
              type: 'realtime',
              model: 'gpt-realtime',
              audio: {
                output: { voice: 'marin' }
              }
            }
          })
        });

        if (!response.ok) {
          const errorText = await response.text();
          console.error('âŒ OpenAI API error:', errorText);
          throw new Error(`Failed to create client secret: ${response.status}`);
        }

        const data = await response.json();
        ephemeralKeyRef.current = data.value;
        return data.value;
      } else {
        // í”„ë¡œë•ì…˜: Supabase Functionì„ í†µí•´ í˜¸ì¶œ
        const { data: { user } } = await supabase.auth.getUser();
        const token = (await supabase.auth.getSession()).data.session?.access_token;

        const response = await fetch(`${import.meta.env.VITE_SUPABASE_URL}/functions/v1/realtime-client-secret`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            ...(token ? { 'Authorization': `Bearer ${token}` } : {}),
            'apikey': import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY || '',
          },
        });

        if (!response.ok) {
          const errorText = await response.text();
          console.error('âŒ Supabase Function error:', errorText);
          throw new Error('Failed to create client secret');
        }
        const { clientSecret } = await response.json();
        ephemeralKeyRef.current = clientSecret;
        return clientSecret;
      }
    } catch (error) {
      console.error('âŒ Ephemeral key ìƒì„± ì˜¤ë¥˜:', error);
      throw error;
    }
  }, [apiKey]);

  // Audio streamer ì„¤ì •
  useEffect(() => {
    if (!audioStreamerRef.current) {
      audioContext({ id: 'audio-out' }).then((audioCtx: AudioContext) => {
        audioStreamerRef.current = new AudioStreamer(audioCtx);
        audioStreamerRef.current
          .addWorklet<any>('vumeter-out', VolMeterWorket, (ev: any) => {
            setVolume(ev.data.volume);
          });
      });
    }
  }, []);

  // Agent ë° Session ì„¤ì •
  useEffect(() => {
    // instructionsê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ìŠ¤í‚µ (React Strict Modeì—ì„œ ì²« ì‹¤í–‰ ì‹œ ìƒíƒœê°€ ì•„ì§ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
    if (!config.instructions || config.instructions.trim().length === 0) {
      // ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ëŠ” ë‚¨ê¸°ë˜, ê²½ê³ ëŠ” ê°œë°œ í™˜ê²½ì—ì„œë§Œ í‘œì‹œ
      if (import.meta.env.DEV) {
        console.log('â„¹ï¸ [OpenAI] Instructions not ready yet, waiting for config update...');
      }
      return;
    }

    console.log('ğŸ¤– [OpenAI] Creating agent with instructions');
    console.log('ğŸ“ [OpenAI] Instructions length:', config.instructions.length);
    console.log('ğŸ“ [OpenAI] Instructions preview:', config.instructions.substring(0, 300));
    console.log('ğŸ”§ [OpenAI] Tools count:', config.tools?.length || 0);
    
    try {
      // ê¸°ì¡´ sessionê³¼ agentê°€ ìˆìœ¼ë©´ ë¨¼ì € ì •ë¦¬ (ì¤‘ë³µ Agent ìƒì„± ë°©ì§€)
      if (sessionRef.current) {
        try {
          console.log('ğŸ§¹ [OpenAI] Cleaning up existing session before creating new one');
          sessionRef.current.close();
        } catch (e) {
          // ignore cleanup errors
        }
        sessionRef.current = null;
      }

      if (agentRef.current) {
        agentRef.current = null;
      }

      // ì—°ê²° ì¤‘ ìƒíƒœë„ ë¦¬ì…‹ (ìƒˆ Agent ìƒì„± ì‹œ ê¸°ì¡´ ì—°ê²° ë¬´íš¨í™”)
      connectingRef.current = false;
      setConnected(false);

      const agentConfig = {
        name: 'ReviewAgent',
        instructions: config.instructions,
        tools: config.tools || [],
        model: 'gpt-4o-realtime-preview-2024-12-17'
      };
      
      console.log('ğŸ”§ [OpenAI] Agent config:', {
        name: agentConfig.name,
        instructionsLength: agentConfig.instructions?.length || 0,
        toolsCount: agentConfig.tools.length,
        model: agentConfig.model
      });
      
      // Instructions ë‚´ìš© ë¡œê¹… (ë””ë²„ê¹…ìš©)
      if (agentConfig.instructions) {
        console.log('ğŸ“ [OpenAI] Instructions preview:', agentConfig.instructions.substring(0, 500));
        
        // Instructionsì— "ì¦‰ì‹œ ì‹œì‘" ì§€ì‹œ í™•ì¸
        if (!agentConfig.instructions.includes('start the conversation IMMEDIATELY')) {
          console.warn('âš ï¸ [OpenAI] Instructions may not include immediate start directive');
        }
      }
      
      // Tools ë‚´ìš© ë¡œê¹… (ë””ë²„ê¹…ìš©)
      if (agentConfig.tools.length > 0) {
        console.log('ğŸ”§ [OpenAI] Tools:', JSON.stringify(agentConfig.tools, null, 2));
      }

      const agent = new RealtimeAgent(agentConfig as any);

      agentRef.current = agent;

      // Session ìƒì„±
      console.log('ğŸ”§ [OpenAI] Creating session');
      const session = new RealtimeSession(agent);
      sessionRef.current = session;
      console.log('âœ… [OpenAI] Session created');

      // setupEventListenersë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì—¬ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
      setupEventListeners(session);

      setIsInitialized(true);
      setSetupComplete(true);
      console.log('âœ… [OpenAI] Agent and session initialized with instructions');
    } catch (error) {
      console.error('âŒ [OpenAI] Error creating agent:', error);
    }

    return () => {
      if (sessionRef.current) {
        try {
          sessionRef.current.close();
        } catch (e) {
          console.error('Session close error:', e);
        }
      }
      sessionRef.current = null;
      agentRef.current = null;
      // cleanupì—ì„œëŠ” isInitializedë¥¼ falseë¡œ ì„¤ì •í•˜ì§€ ì•ŠìŒ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    };
  }, [config.instructions, config.tools]); // isInitializedë¥¼ ì˜ì¡´ì„±ì—ì„œ ì œê±°

  // OpenAI ì´ë²¤íŠ¸ë¥¼ Gemini ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜
  const setupEventListeners = (session: RealtimeSession) => {
    // session.created/updated ì´ë²¤íŠ¸ëŠ” RealtimeAgentì˜ instructionsê°€ ìë™ìœ¼ë¡œ ì ìš©ë˜ë¯€ë¡œ ë¶ˆí•„ìš”

    // ì˜¤ë””ì˜¤ ì¶œë ¥ ì²˜ë¦¬
    (session as any).on('response.audio.delta', (data: any) => {
      if (data?.delta && audioStreamerRef.current) {
        const audioData = base64ToArrayBuffer(data.delta);
        audioStreamerRef.current.addPCM16(new Uint8Array(audioData));
      }
    });

    // Speech ì´ë²¤íŠ¸
    (session as any).on('response.speech_started', () => {
      triggerEvent('audio', new ArrayBuffer(0));
      setSetupComplete(true);
    });

    (session as any).on('response.speech_stopped', () => {
      triggerEvent('turncomplete', null);
    });

    // Transcript ì´ë²¤íŠ¸
    (session as any).on('input_audio_buffer.transcript.completed', (data: any) => {
      if (data?.transcript) {
        triggerEvent('content', { text: data.transcript });
      }
    });

    (session as any).on('conversation.item.added', (item: any) => {
      if (item?.role === 'assistant' && item?.content) {
        const text = Array.isArray(item.content)
          ? item.content.map((c: any) => c?.text || '').join(' ')
          : item.content;
        if (text) {
          triggerEvent('content', { text });
        }
      }
    });

    // Tool call ì´ë²¤íŠ¸ (OpenAIëŠ” tool callsë¥¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬)
    (session as any).on('response.function_call_arguments_completed', (data: any) => {
      if (data?.function_call) {
        triggerEvent('toolcall', {
          functionCalls: [{
            id: data.function_call.id || Date.now().toString(),
            name: data.function_call.name,
            args: data.function_call.arguments
          }]
        });
      }
    });
  };

  // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ê´€ë¦¬ (Gemini ìŠ¤íƒ€ì¼ í˜¸í™˜)
  const triggerEvent = (event: string, data: any) => {
    const handlers = eventHandlersRef.current.get(event);
    if (handlers) {
      handlers.forEach(handler => handler(data));
    }
  };

  const connect = useCallback(async () => {
    // ì¤‘ë³µ ì—°ê²° ë°©ì§€
    if (connectingRef.current) {
      console.log('â¸ï¸ [OpenAI] Already connecting, ignoring duplicate call');
      return;
    }

    if (connected) {
      console.log('â¸ï¸ [OpenAI] Already connected, ignoring duplicate call');
      return;
    }

    // Agentê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ (AgentëŠ” configë¡œë¶€í„° ìƒì„±ë˜ì–´ì•¼ í•¨)
    if (!agentRef.current) {
      console.error('âŒ [OpenAI] Agent not initialized');
      console.log('ğŸ” [OpenAI] Debug:', {
        hasSession: !!sessionRef.current,
        hasAgent: !!agentRef.current,
        hasInstructions: !!config.instructions,
        isInitialized
      });
      return;
    }

    // Sessionì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„± (ì¬ì—°ê²° ì§€ì›)
    if (!sessionRef.current) {
      console.log('ğŸ”„ [OpenAI] Creating new session for reconnection...');
      sessionRef.current = new RealtimeSession(agentRef.current);
      setupEventListeners(sessionRef.current);
    }

    connectingRef.current = true;

    try {
      console.log('ğŸ”Œ [OpenAI] Starting connection...');
      
      let clientSecret = ephemeralKeyRef.current;
      if (!clientSecret) {
        console.log('ğŸ”‘ [OpenAI] Generating ephemeral key...');
        clientSecret = await generateEphemeralKey();
      }

      console.log('ğŸ”— [OpenAI] Connecting to Realtime API...');
      await sessionRef.current.connect({
        apiKey: clientSecret || ''
      });

      console.log('âœ… [OpenAI] Connected successfully');
      setConnected(true);
      
      // Agent instructionsì— ë”°ë¼ ì¦‰ì‹œ ì‘ë‹µ ìƒì„± (conversation.item.create ì—†ì´)
      setTimeout(async () => {
        try {
          console.log('ğŸ¤ [OpenAI] Triggering agent to start conversation...');
          const session = sessionRef.current as any;
          const ws = session?.ws || session?._ws || session?.connection?.ws;
          
          if (ws && ws.readyState === WebSocket.OPEN) {
            // Agentì˜ instructionsì— "ì¦‰ì‹œ ì¸ì‚¬í•˜ê³  ì‹œì‘í•˜ë¼"ê°€ ìˆìœ¼ë¯€ë¡œ
            // response.createë§Œ ë³´ë‚´ë©´ Agentê°€ instructionsëŒ€ë¡œ í–‰ë™í•¨
            ws.send(JSON.stringify({ type: 'response.create' }));
            console.log('âœ… [OpenAI] Sent response.create - agent should follow instructions');
          } else {
            console.warn('âš ï¸ [OpenAI] WebSocket not available');
          }
        } catch (error) {
          console.error('âŒ [OpenAI] Error triggering initial response:', error);
        }
      }, 500);

      // Audio recorder ì‹œì‘
      if (!audioRecorderRef.current) {
        console.log('ğŸ¤ [OpenAI] Starting audio recorder...');
        audioRecorderRef.current = new AudioRecorder(16000);
        audioRecorderRef.current.on('data', (base64Audio: string) => {
          if (sessionRef.current) {
            try {
              // OpenAI Realtime APIì˜ audio input í˜•ì‹ìœ¼ë¡œ ì „ì†¡
              // ì£¼ì˜: ControlTrayì˜ sendRealtimeInputì„ í†µí•´ ì˜¤ë””ì˜¤ê°€ ì „ì†¡ë˜ë¯€ë¡œ
              // ì—¬ê¸°ì„œëŠ” ì§ì ‘ ì „ì†¡í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆìŒ
              // í•˜ì§€ë§Œ ì¼ë¶€ ê²½ë¡œì—ì„œëŠ” ì—¬ê¸°ì„œë„ ì „ì†¡ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
              const session = sessionRef.current as any;
              
              // ë°©ë²• 1: inputAudioBuffer.append
              if (session.inputAudioBuffer && typeof session.inputAudioBuffer.append === 'function') {
                session.inputAudioBuffer.append({
                  audio: base64Audio
                });
              } 
              // ë°©ë²• 2: session.append
              else if (session.append && typeof session.append === 'function') {
                session.append({
                  type: 'input_audio_buffer.append',
                  audio: base64Audio
                });
              }
              // ê²½ê³  ì œê±° - ControlTrayì—ì„œ ì´ë¯¸ ì²˜ë¦¬í•˜ê³  ìˆìœ¼ë¯€ë¡œ ë¬´ì‹œ
            } catch (error) {
              console.error('âŒ [OpenAI] Error sending audio:', error);
            }
          }
        });
        await audioRecorderRef.current.start();
        console.log('âœ… [OpenAI] Audio recorder started');
      }
    } catch (error) {
      console.error('âŒ [OpenAI] Connection error:', error);
      setConnected(false);
    } finally {
      connectingRef.current = false;
    }
  }, [generateEphemeralKey, config.instructions, connected]); // connected ì¶”ê°€

  const disconnect = useCallback(async () => {
    console.log('ğŸ”Œ [OpenAI] Disconnecting...');
    connectingRef.current = false; // ì—°ê²° ì¤‘ í”Œë˜ê·¸ ë¦¬ì…‹

    if (audioRecorderRef.current) {
      await audioRecorderRef.current.stop();
      audioRecorderRef.current = null;
    }

    if (sessionRef.current) {
      try {
        sessionRef.current.close();
      } catch (e) {
        console.error('Disconnect error:', e);
      }
      sessionRef.current = null;
    }

    // AgentëŠ” ìœ ì§€ (ì¬ì—°ê²° ì‹œ ì¬ì‚¬ìš©)
    // agentRef.currentëŠ” nullë¡œ ì„¤ì •í•˜ì§€ ì•ŠìŒ

    setConnected(false);
    setSetupComplete(false);
    console.log('âœ… [OpenAI] Disconnected');
  }, []);

  const setConfig = useCallback((newConfig: LiveConnectConfig | { instructions?: string; tools?: any[] }) => {
    // Gemini ìŠ¤íƒ€ì¼ configì¸ì§€ í™•ì¸ (systemInstructionì´ ìˆëŠ”ì§€)
    if ('systemInstruction' in newConfig || 'responseModalities' in newConfig) {
      console.log('ğŸ”„ [OpenAI] Converting Gemini config to OpenAI instructions');
      console.log('ğŸ“¥ [OpenAI] Input config keys:', Object.keys(newConfig));
      
      const converted = convertGeminiConfigToOpenAI(newConfig as LiveConnectConfig);
      
      console.log('âœ… [OpenAI] Converted instructions length:', converted.instructions.length);
      console.log('âœ… [OpenAI] Converted instructions preview:', converted.instructions.substring(0, 200));
      console.log('âœ… [OpenAI] Converted tools count:', converted.tools.length);
      
      if (!converted.instructions || converted.instructions.trim().length === 0) {
        console.error('âŒ [OpenAI] Warning: Converted instructions are empty!');
        return; // ë¹ˆ instructionsê°€ ìˆìœ¼ë©´ ì„¤ì •í•˜ì§€ ì•ŠìŒ
      }
      
      // ì¦‰ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸ (Reactì˜ ë°°ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ ê³ ë ¤)
      setConfigState(converted);
      console.log('ğŸ’¾ [OpenAI] Config state updated');
    } else {
      // ì´ë¯¸ OpenAI í˜•ì‹
      console.log('ğŸ“¥ [OpenAI] Direct OpenAI config provided');
      const instructions = (newConfig as any).instructions;
      console.log('ğŸ“ [OpenAI] Instructions length:', instructions?.length || 0);
      
      if (!instructions || instructions.trim().length === 0) {
        console.warn('âš ï¸ [OpenAI] No instructions provided in direct config');
        return;
      }
      
      setConfigState(newConfig as { instructions?: string; tools?: any[] });
      console.log('ğŸ’¾ [OpenAI] Config state updated');
    }
  }, []);

  // Gemini í˜¸í™˜ ë©”ì„œë“œë“¤
  const send = useCallback((parts: Array<{ text: string }>) => {
    if (!sessionRef.current) {
      console.warn('âš ï¸ [OpenAI] Session not available for send');
      return;
    }
    
    const text = parts.map(p => p.text).join(' ');
    const session = sessionRef.current as any;
    
    try {
      // OpenAI Realtime APIì—ì„œ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ëŠ” ë°©ë²•
      // OpenAIëŠ” ì£¼ë¡œ ì˜¤ë””ì˜¤ ê¸°ë°˜ì´ë¯€ë¡œ, í…ìŠ¤íŠ¸ëŠ” ì œí•œì 
      // createResponseê°€ ìˆìœ¼ë©´ í˜¸ì¶œ, ì—†ìœ¼ë©´ instructionsì— ì˜ì¡´
      if (typeof session.createResponse === 'function') {
        console.log('ğŸ“¤ [OpenAI] Triggering response (text will be ignored, using instructions):', text);
        // ì¸ì ì—†ì´ í˜¸ì¶œí•˜ë©´ instructionsì— ë”°ë¼ ìë™ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        session.createResponse();
      } else {
        // createResponseê°€ ì—†ìœ¼ë©´ instructionsì— ì˜ì¡´
        // Instructionsì— "IMMEDIATELY start speaking"ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì‘ë‹µ ì‹œì‘
        console.log('â„¹ï¸ [OpenAI] createResponse ì—†ìŒ - Instructionsì— ì˜ì¡´í•˜ì—¬ ìë™ ì‘ë‹µ');
      }
    } catch (error) {
      console.error('âŒ [OpenAI] Error sending message:', error);
    }
  }, []);

  const sendToolResponse = useCallback((response: any) => {
    if (!sessionRef.current) return;
    // OpenAIì˜ tool response í˜•ì‹ì— ë§ê²Œ ë³€í™˜ í•„ìš”
    console.log('Tool response (OpenAI):', response);
  }, []);

  const on = useCallback((event: string, handler: Function) => {
    if (!eventHandlersRef.current.has(event)) {
      eventHandlersRef.current.set(event, new Set());
    }
    eventHandlersRef.current.get(event)?.add(handler);
  }, []);

  const off = useCallback((event: string, handler: Function) => {
    eventHandlersRef.current.get(event)?.delete(handler);
  }, []);

  // Gemini GenAILiveClient ìŠ¤íƒ€ì¼ì˜ í´ë¼ì´ì–¸íŠ¸ ë˜í¼
  const clientWrapper = useMemo(() => {
    return {
      session: sessionRef.current,
      send,
      sendToolResponse,
      sendRealtimeInput: (chunks: Array<{ mimeType: string; data: string }>) => {
        // ControlTrayì—ì„œ í˜¸ì¶œí•˜ëŠ” sendRealtimeInput ì§€ì›
        if (!sessionRef.current) return;
        const session = sessionRef.current as any;
        
        chunks.forEach((chunk) => {
          if (chunk.mimeType.includes('audio')) {
            // Audio input ì²˜ë¦¬ - OpenAI RealtimeSessionì˜ ì‹¤ì œ API ì‚¬ìš©
            try {
              // ë°©ë²• 1: inputAudioBuffer.append (ê°€ì¥ ì¼ë°˜ì )
              if (session.inputAudioBuffer && typeof session.inputAudioBuffer.append === 'function') {
                session.inputAudioBuffer.append({
                  audio: chunk.data
                });
              } 
              // ë°©ë²• 2: sessionì˜ append ë©”ì„œë“œ (ì¼ë¶€ ë²„ì „)
              else if (session.append && typeof session.append === 'function') {
                session.append({
                  type: 'input_audio_buffer.append',
                  audio: chunk.data
                });
              }
              // ë°©ë²• 3: ì§ì ‘ ë‚´ë¶€ ë©”ì„œë“œ í˜¸ì¶œ (í´ë°±)
              else if ((session as any)._sendAudioInput || (session as any).sendAudioInput) {
                const sendAudioMethod = (session as any)._sendAudioInput || (session as any).sendAudioInput;
                if (typeof sendAudioMethod === 'function') {
                  sendAudioMethod(chunk.data);
                }
              } else {
                // ê²½ê³  ë¡œê·¸ ì œê±° - ControlTrayì—ì„œ ì´ë¯¸ ì˜¤ë””ì˜¤ë¥¼ ì „ì†¡í•˜ê³  ìˆìœ¼ë¯€ë¡œ
                // ì´ ê²½ë¡œëŠ” ì‹¤ì œë¡œ ì‚¬ìš©ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
              }
            } catch (error) {
              console.error('âŒ [OpenAI] Error sending audio input:', error);
            }
          }
        });
      },
      createResponse: async () => {
        const session = sessionRef.current as any;
        if (!session) {
          console.warn('âš ï¸ [OpenAI] No session available for createResponse');
          return;
        }
        
        console.log('ğŸ¤ [OpenAI] createResponse í˜¸ì¶œë¨');
        
        try {
          // sendMessage ë©”ì„œë“œ ì‚¬ìš©
          if (typeof session.sendMessage === 'function') {
            console.log('ğŸ“¤ [OpenAI] sendMessage ë©”ì„œë“œ ì‚¬ìš©');
            await session.sendMessage('Continue the conversation.');
            console.log('âœ… [OpenAI] ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ');
          } else {
            console.warn('âš ï¸ [OpenAI] sendMessage ë©”ì„œë“œ ì—†ìŒ');
          }
        } catch (error) {
          console.error('âŒ [OpenAI] Error creating response:', error);
        }
      },
      on,
      off,
      connect,
      disconnect,
      status: connected ? 'connected' : 'disconnected',
    } as any;
  }, [send, sendToolResponse, on, off, connect, disconnect, connected]);

  return {
    client: clientWrapper,
    agent: agentRef.current,
    setConfig,
    config,
    model,
    setModel,
    connected,
    setupComplete,
    connect,
    disconnect,
    volume,
    send,
    sendToolResponse,
    on,
    off,
  };
}

// Base64ë¥¼ ArrayBufferë¡œ ë³€í™˜
function base64ToArrayBuffer(base64: string): ArrayBuffer {
  const binaryString = atob(base64);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes.buffer;
}

